You are an expert in Cypher and Neo4j. I need your help to interpret and model ESG data structured as a JSON object in the following format:

{ "all_data": data }

Here, data is a list of lists, where each inner list corresponds to a row of data, with the first row as headers.

Objective: Generate a flexible Cypher query that dynamically analyzes the input structure to determine core entities and relationships, create an appropriate Neo4j model, and import the data. This model should adapt to varying data structures, only assuming that fields related to ESG fall within the categories of Environmental, Social, or Governance metrics.

Phase 1: Data Analysis and Model Inference
Output your reasoning in the "explanation" field of the JSON response:

1. Interpret the Data Structure: Analyze the header row to identify potential entities and relationships within the data, based on the headers and a sampling of values.

* Entity Types: Detect primary entities that should serve as unique nodes.
* Date or Time: Identify any fields that may represent dates or years, likely used to distinguish different records or reports.
* Categories: Determine fields that may serve as categories or classifications (e.g., industry, sector).
* ESG-Related Fields: Identify fields with ESG relevance, categorizing them under Environment, Social, or Governance.

2. Define Model Structure:

* Describe the model based on the inferred entities and relationships:
    * Primary Entity Nodes: For each unique primary entity, create a node (e.g., a Company).
    * Report Nodes: For each row in the data, create a Report node, linking it to the primary entity node and any date or year nodes.
    * ESG Nodes: Group ESG-related fields into Environment, Social, and Governance nodes.
    * Categorical Nodes: Create category nodes as needed.
    * Date/Year Nodes: Create nodes to represent years, allowing linkage of reports by year.

Add this reasoning to the "explanation" field in the JSON output.

Phase 2: Cypher Query Generation
Using the model structure from Phase 1, create a Cypher query to import the data. Place only the Cypher query itself in the "cypher_query" field.

1. Data Processing Instructions:

* Start with `WITH $data AS data UNWIND data.all_data[1..] AS row WITH data.all_data[0] AS headers, row WITH headers, row`.
* Use data.all_data[0] as headers and process only the data rows.
* Construct mappings between headers and values manually without using apoc.map.fromLists.
* Set default values for missing or empty fields.

2. Node and Relationship Creation:

* Create nodes for each entity, linking to any category or industry nodes.
* Create Report nodes for each row, linked to the relevant primary entity, date, and ESG nodes.
* For each ESG-related field, create separate Environment, Social, and Governance nodes.
* Create Year nodes based on date fields.

Example Output Format:

{ "explanation": "EXPLANATION CREATED BY PHASE 1", "cypher_query": "CYPHER QUERY CREATED BY PHASE 2" }

Important Notes:
* Output as JSON: The final output should be strictly in valid JSON format with two fields: "cypher_query" for the Cypher script and "explanation" for reasoning.
* Default Values: Apply default values for missing or empty fields.
* Flexibility: The query should be adaptable to various data structures, avoiding hard-coded field names (except for ESG categories).
